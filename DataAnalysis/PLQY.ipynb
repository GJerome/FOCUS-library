{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# folder with data\n",
    "folder = Path('C:/Users/rigter/Desktop/Jupyter workspace/231026 SB Pietro/proper_measurements/')\n",
    "\n",
    "Wave_Emission=700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% importing packages, defining functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "cmap = plt.get_cmap('magma')\n",
    "\n",
    "##%% definition of the big master data_import function, now for SPARS\n",
    "\n",
    "def data_import(filename): \n",
    "    #function to open the data file, meant to work for different loops and formats\n",
    "    text = open(filename, \"r\").readlines()\n",
    "    k = 0\n",
    "    i_data = 0\n",
    "    while i_data == 0: #find where the different parts of the data file start\n",
    "        k = k + 1\n",
    "        if text[k][:6] == 'Index\\t': #start of actual data\n",
    "            i_data = k\n",
    "            \n",
    "    df = pd.read_csv(filename, delimiter = '\\t', skiprows = i_data, index_col = 0)\n",
    "\n",
    "    #remove phase data\n",
    "    #changing some annoying column names\n",
    "    for col in df.columns:\n",
    "        if 'Aotf' in col:\n",
    "            newname = 'wl'\n",
    "        elif 'Piezo' in col:\n",
    "            newname = col[6]\n",
    "        elif 'Magnitude' in col:\n",
    "            newname = col[0]\n",
    "        elif 'Flip' in col:\n",
    "            newname = 'LPSP'  ##value = 1 for SP, 2 for LP \n",
    "        else:\n",
    "            newname = col\n",
    "        df.rename(columns = {col: newname}, inplace = True)\n",
    "        \n",
    "        if 'Phase' in col:\n",
    "            df.drop(col, axis = 1, inplace = True)\n",
    "        if 'FocusC' in col:\n",
    "            df.drop(col, axis = 1, inplace = True)  \n",
    "      \n",
    "    #taking the average of repeats and building a dataframe with the standard deviations\n",
    "    if 'Repeat [x]' in df.columns:\n",
    "        if 'X' and 'LPSP' and 'wl' in df.columns:\n",
    "            # print('X and LPSP')\n",
    "            df_sd = df.groupby(['wl', 'X', 'LPSP'], as_index = False).std()\n",
    "            df = df.groupby(['wl', 'X', 'LPSP'], as_index = False).mean()\n",
    "        elif 'X' and 'wl' in df.columns:\n",
    "            # print('X')\n",
    "            df_sd = df.groupby(['wl', 'X'], as_index = False).std()\n",
    "            df = df.groupby(['wl', 'X'], as_index = False).mean()\n",
    "        elif 'wl' in df.columns:\n",
    "            df_sd = df.groupby(['wl'], as_index = False).std()\n",
    "            df = df.groupby(['wl'], as_index = False).mean()\n",
    "        else: \n",
    "            df_sd = df.groupby(['LPSP'], as_index = False).std()\n",
    "            df = df.groupby(['LPSP'], as_index = False).mean()\n",
    "            print('Carefull we are only selecting on the filter value')\n",
    "        df.drop('Repeat [x]', axis = 1, inplace = True)\n",
    "        df_sd.drop('Repeat [x]', axis = 1, inplace = True)\n",
    "    else:\n",
    "        df_sd = pd.DataFrame({})\n",
    "        for col in df.columns:\n",
    "            df_sd[col] = []\n",
    "    #normalize to beam monitor\n",
    "    \n",
    "    if 'R' in df.columns: \n",
    "        # print('yes')\n",
    "        df['RbyM'] = df.R / df.M\n",
    "        df_sd['RbyM'] = abs(df.RbyM) * np.sqrt((df_sd.R/df.R)**2 \\\n",
    "                                                + (df_sd.M/df.M)**2)\n",
    "            \n",
    "    if 'I' in df.columns:\n",
    "        df['IbyM'] = df.I / df.M\n",
    "        df_sd['IbyM'] = abs(df.IbyM) * np.sqrt((df_sd.I/df.I)**2 \\\n",
    "                                                  + (df_sd.M/df.M)**2)\n",
    "               \n",
    "    # df = df.drop(['Index'], axis = 1)\n",
    "    # df_sd = df_sd.drop(['Index', 'Repeat'], axis = 1)\n",
    "    \n",
    "    return df, df_sd\n",
    "\n",
    "def abscalculator(sampleSP, mirror, miss):\n",
    "    df = pd.DataFrame({'X': sampleSP.X,\n",
    "                       'Z': sampleSP.Z,\n",
    "                       'AR': (sampleSP.RbyM/mirror),\n",
    "                       'AIS': (sampleSP.ISbyM/miss),\n",
    "    })\n",
    "    df['A'] = 1 - df.AR - df.AIS\n",
    "    Amap = df.pivot(index = 'Z', columns = 'X', values = 'A')\n",
    "    return df, Amap \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define responsisvity of the detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert responsivity data from [A/W] to [A/photon flux]\n",
    "\n",
    "h = 6.6260e-34 #(J s) planck \n",
    "c = 2.9979e8 #(m/s) speed of light \n",
    "\n",
    "\n",
    "#ratio of generated photocurrent to incident power (A/W)\n",
    "responsivity = pd.read_csv(\"./DataPLQY/responsivity.csv\")   \n",
    "\n",
    "#the energy of photons (J)    \n",
    "responsivity['Eph'] = (h * c * 1e9)/responsivity.wavelength\n",
    "\n",
    "responsivity['ampsbyph'] = responsivity.Eph * responsivity.responsivity\n",
    "\n",
    "#interpolating responsivity to get entry for each Lex\n",
    "interp_df = pd.DataFrame({'wavelength': np.arange(200, 1101, 2)})\n",
    "resp = pd.merge(interp_df, responsivity, on = 'wavelength', how = 'left')\n",
    "\n",
    "resp = resp.interpolate()\n",
    "\n",
    "#selecting resp at em \n",
    "\n",
    "resp_em = resp[(resp.wavelength == Wave_Emission)].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carefull we are only selecting on the filter value\n",
      "Carefull we are only selecting on the filter value\n",
      "Carefull we are only selecting on the filter value\n",
      "Carefull we are only selecting on the filter value\n",
      "Carefull we are only selecting on the filter value\n",
      "Carefull we are only selecting on the filter value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing all reference files, defining responsivity at the right wavelength\n",
    "\n",
    "PD_em, PD_em_std = data_import('./DataPLQY/20240117_165748_PDcal_em/result.txt')\n",
    "PD_ex, PD_ex_std = data_import('./DataPLQY/20240117_165611_PDcal/result.txt')\n",
    "\n",
    "#place proper ex and em wls in 770/780 and 550 spots\n",
    "resp_em = responsivity[(responsivity.wavelength == 720) ^ (responsivity.wavelength == 780)].mean()\n",
    "resp_ex = responsivity[responsivity.wavelength == 450].mean()\n",
    "\n",
    "phflux_ex = PD_ex.IbyM.mean() / resp_ex.ampsbyph\n",
    "phflux_em = PD_em.IbyM.mean() / resp_em.ampsbyph\n",
    "\n",
    "\n",
    "\n",
    "mirror_em, mirror_em_std  = data_import('./DataPLQY/20240117_164734_LP_mirror/result.txt')\n",
    "mirror_ex,mirror_ex_std = data_import('./DataPLQY/20240117_164456_SP_mirror/result.txt') \n",
    "\n",
    "miss_em,miss_em_std = data_import('./DataPLQY/20240117_163018_LP_miss/result.txt')\n",
    "miss_ex,miss_em_std = data_import('./DataPLQY/20240117_160312_SP_miss/result.txt')\n",
    "\n",
    "Reff_em = phflux_em / mirror_em.RbyM.mean()\n",
    "ISeff_em = phflux_em / miss_em.IbyM.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "abs_PLQY_calc() missing 2 required positional arguments: 'miss_file_em' and 'miss_file_ex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#%%    \u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m Sample \u001b[38;5;241m=\u001b[39m \u001b[43mabs_PLQY_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munpassivated_XZ-map_l-exc550nm_LP650SP650.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[0;32m     30\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(Sample\u001b[38;5;241m.\u001b[39mpivot(index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLQY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: abs_PLQY_calc() missing 2 required positional arguments: 'miss_file_em' and 'miss_file_ex'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#%% importing unencapsulated sample map, calculating absorptance\n",
    "\n",
    "def abs_PLQY_calc(sample_file, miss_file_em, miss_file_ex):\n",
    "    \n",
    "    miss_em = data_import(miss_file_em)\n",
    "    miss_ex = data_import(miss_file_ex)\n",
    "    ISeff_em = phflux_em / miss_em.ISbyM.mean()\n",
    "    \n",
    "    sample_LP, sample_SP = data_import(sample_file) \n",
    "    sample_abs = abscalculator(sample_SP, mirror_ex.RbyM.mean(), miss_ex.IbyM.mean())\n",
    "        \n",
    "    R_photons_em = sample_LP.RbyM * Reff_em\n",
    "    IS_photons_em = sample_LP.IbyM * ISeff_em\n",
    "\n",
    "    sample_PL = R_photons_em + IS_photons_em\n",
    "\n",
    "    df = sample_abs[0].drop(['AIS', 'AR'], axis = 1)\n",
    "    df['absflux'] = phflux_ex * df.A\n",
    "    df['PLflux'] = sample_PL\n",
    "    df['PLQY'] = 100 * df.PLflux/df.absflux\n",
    "    return df \n",
    "\n",
    "\n",
    "#%%    \n",
    "\n",
    "Sample = abs_PLQY_calc('./DataPLQY/20240117_145209_PLQY map/result.txt')\n",
    "\n",
    "#%%\n",
    "\n",
    "fig = plt.imshow(Sample.pivot(index = 'Z', columns = 'X', values = 'PLQY'))\n",
    "\n",
    "plt.colorbar(fig, label = 'PLQY')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
